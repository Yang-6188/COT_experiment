#!/usr/bin/env python3
"""
å¢å¼ºå‹HALT-CoTå®éªŒé…ç½®æ–‡ä»¶
é…ç½®æ–‡ä»¶ç”¨äºç®¡ç†æ¨¡å‹ã€æ•°æ®è·¯å¾„ã€å®éªŒå‚æ•°ç­‰
"""

import json
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict

# ============================================================================
# åŸºç¡€è·¯å¾„é…ç½®
# ============================================================================
BASE_DIR = Path("/root/autodl-tmp")
CONFIG_DIR = BASE_DIR / "config_entropy"
DATA_DIR = BASE_DIR / "data"
RESULTS_DIR = BASE_DIR / "results_entropy"
PLOTS_DIR = RESULTS_DIR / "plots"

# ç¡®ä¿ç›®å½•å­˜åœ¨
CONFIG_DIR.mkdir(parents=True, exist_ok=True)
DATA_DIR.mkdir(parents=True, exist_ok=True)
RESULTS_DIR.mkdir(parents=True, exist_ok=True)
PLOTS_DIR.mkdir(parents=True, exist_ok=True)

# ============================================================================
# é…ç½®æ•°æ®ç±»
# ============================================================================
@dataclass
class ModelConfig:
    """æ¨¡å‹ç›¸å…³é…ç½®"""
    name: str = "Qwen/Qwen2.5-7B-Instruct"
    torch_dtype: str = "float16"  # æ”¯æŒ float16, float32, bfloat16
    device_map: str = "auto"
    trust_remote_code: bool = True
    use_cache: bool = True

@dataclass
class DataConfig:
    """æ•°æ®ç›¸å…³é…ç½®"""
    data_path: str = str(DATA_DIR / "gsm8k_test.json")
    sample_size: int = 12
    max_samples: int = 100  # æ•°æ®é›†æœ€å¤§æ ·æœ¬æ•°é™åˆ¶
    shuffle_data: bool = False
    random_seed: int = 42

@dataclass
class GenerationConfig:
    """ç”Ÿæˆç›¸å…³é…ç½®"""
    max_tokens: int = 512
    temperature: float = 0.0  # ç¡®å®šæ€§ç”Ÿæˆ
    do_sample: bool = False
    top_p: float = 0.9
    top_k: int = 50
    repetition_penalty: float = 1.0

@dataclass
class ProbeConfig:
    """æ¢æµ‹ç³»ç»Ÿé…ç½®"""
    cooldown: int = 8  # æ¢æµ‹é—´éš”ï¼ˆtokenæ•°ï¼‰
    min_cooldown: int = 5  # æœ€å°æ¢æµ‹é—´éš”
    max_cooldown: int = 20  # æœ€å¤§æ¢æµ‹é—´éš”
    probe_max_tokens: int = 20  # æ¢æµ‹ç”Ÿæˆçš„æœ€å¤§tokenæ•°
    entropy_threshold: float = 0.6  # ä½ç†µé˜ˆå€¼
    confidence_threshold: float = 0.8  # ç½®ä¿¡åº¦é˜ˆå€¼
    enable_dynamic_cooldown: bool = True  # åŠ¨æ€è°ƒæ•´æ¢æµ‹é—´éš”

@dataclass
class VisualizationConfig:
    """å¯è§†åŒ–é…ç½®"""
    enable_plots: bool = True
    plot_dpi: int = 200
    figure_width: int = 18
    figure_height_per_row: int = 5
    plot_columns: int = 3
    save_individual_plots: bool = False
    color_scheme: Dict[str, str] = None

    def __post_init__(self):
        if self.color_scheme is None:
            self.color_scheme = {
                'intermediate': '#3498db',
                'calculation': '#f39c12', 
                'conclusion': '#2ecc71',
                'answer_signal': '#e74c3c'
            }

@dataclass
class ExperimentConfig:
    """å®éªŒé…ç½®"""
    debug: bool = True
    verbose: bool = True
    save_raw_responses: bool = True
    save_probe_details: bool = True
    enable_text_cleaning: bool = True
    strict_answer_extraction: bool = False

@dataclass
class OutputConfig:
    """è¾“å‡ºé…ç½®"""
    results_dir: str = str(RESULTS_DIR)
    plots_dir: str = str(PLOTS_DIR)
    save_json: bool = True
    save_csv: bool = False
    json_indent: int = 2
    filename_timestamp: bool = True

@dataclass
class HaltCoTConfig:
    """å®Œæ•´çš„HALT-CoTå®éªŒé…ç½®"""
    model: ModelConfig
    data: DataConfig
    generation: GenerationConfig
    probe: ProbeConfig
    visualization: VisualizationConfig
    experiment: ExperimentConfig
    output: OutputConfig

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'model': asdict(self.model),
            'data': asdict(self.data),
            'generation': asdict(self.generation),
            'probe': asdict(self.probe),
            'visualization': asdict(self.visualization),
            'experiment': asdict(self.experiment),
            'output': asdict(self.output)
        }

    def save_to_file(self, filepath: Optional[Path] = None):
        """ä¿å­˜é…ç½®åˆ°JSONæ–‡ä»¶"""
        if filepath is None:
            filepath = CONFIG_DIR / "halt_cot_config.json"
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)
        print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {filepath}")

    @classmethod
    def load_from_file(cls, filepath: Path) -> 'HaltCoTConfig':
        """ä»JSONæ–‡ä»¶åŠ è½½é…ç½®"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return cls(
            model=ModelConfig(**data['model']),
            data=DataConfig(**data['data']),
            generation=GenerationConfig(**data['generation']),
            probe=ProbeConfig(**data['probe']),
            visualization=VisualizationConfig(**data['visualization']),
            experiment=ExperimentConfig(**data['experiment']),
            output=OutputConfig(**data['output'])
        )

# ============================================================================
# é¢„è®¾é…ç½®æ¨¡æ¿
# ============================================================================
class ConfigTemplates:
    """é…ç½®æ¨¡æ¿é›†åˆ"""
    
    @staticmethod
    def default_config() -> HaltCoTConfig:
        """é»˜è®¤é…ç½®"""
        return HaltCoTConfig(
            model=ModelConfig(),
            data=DataConfig(),
            generation=GenerationConfig(),
            probe=ProbeConfig(),
            visualization=VisualizationConfig(),
            experiment=ExperimentConfig(),
            output=OutputConfig()
        )
    
    @staticmethod
    def quick_test_config() -> HaltCoTConfig:
        """å¿«é€Ÿæµ‹è¯•é…ç½®"""
        config = ConfigTemplates.default_config()
        config.data.sample_size = 5
        config.generation.max_tokens = 256
        config.probe.cooldown = 5
        config.experiment.debug = True
        config.experiment.verbose = True
        return config
    
    @staticmethod
    def large_scale_config() -> HaltCoTConfig:
        """å¤§è§„æ¨¡å®éªŒé…ç½®"""
        config = ConfigTemplates.default_config()
        config.data.sample_size = 100
        config.generation.max_tokens = 1024
        config.probe.cooldown = 10
        config.visualization.plot_columns = 4
        config.experiment.debug = False
        return config
    
    @staticmethod
    def high_precision_config() -> HaltCoTConfig:
        """é«˜ç²¾åº¦åˆ†æé…ç½®"""
        config = ConfigTemplates.default_config()
        config.generation.torch_dtype = "float32"
        config.probe.cooldown = 3
        config.probe.probe_max_tokens = 30
        config.experiment.strict_answer_extraction = True
        config.visualization.plot_dpi = 300
        return config

# ============================================================================
# é…ç½®éªŒè¯å™¨
# ============================================================================
class ConfigValidator:
    """é…ç½®éªŒè¯å™¨"""
    
    @staticmethod
    def validate_config(config: HaltCoTConfig) -> List[str]:
        """éªŒè¯é…ç½®ï¼Œè¿”å›è­¦å‘Šæˆ–é”™è¯¯ä¿¡æ¯"""
        warnings = []
        
        # éªŒè¯è·¯å¾„
        if not Path(config.data.data_path).exists():
            warnings.append(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {config.data.data_path}")
        
        # éªŒè¯æ•°å€¼èŒƒå›´
        if config.data.sample_size <= 0:
            warnings.append("âŒ sample_size å¿…é¡»å¤§äº0")
        
        if config.generation.max_tokens <= 0:
            warnings.append("âŒ max_tokens å¿…é¡»å¤§äº0")
        
        if config.probe.cooldown < 1:
            warnings.append("âŒ cooldown å¿…é¡»å¤§äºç­‰äº1")
        
        # éªŒè¯æ¨¡å‹å…¼å®¹æ€§
        if "Qwen" in config.model.name and config.generation.temperature > 0 and not config.generation.do_sample:
            warnings.append("âš ï¸ ä½¿ç”¨temperature>0æ—¶å»ºè®®è®¾ç½®do_sample=True")
        
        # éªŒè¯è¾“å‡ºç›®å½•
        try:
            Path(config.output.results_dir).mkdir(parents=True, exist_ok=True)
            Path(config.output.plots_dir).mkdir(parents=True, exist_ok=True)
        except Exception as e:
            warnings.append(f"âŒ æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {e}")
        
        return warnings

# ============================================================================
# é…ç½®ç®¡ç†å™¨
# ============================================================================
class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    @staticmethod
    def create_default_config_file():
        """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
        config = ConfigTemplates.default_config()
        config.save_to_file()
        return config
    
    @staticmethod
    def create_all_template_configs():
        """åˆ›å»ºæ‰€æœ‰æ¨¡æ¿é…ç½®æ–‡ä»¶"""
        templates = {
            'default': ConfigTemplates.default_config(),
            'quick_test': ConfigTemplates.quick_test_config(),
            'large_scale': ConfigTemplates.large_scale_config(),
            'high_precision': ConfigTemplates.high_precision_config()
        }
        
        for name, config in templates.items():
            filepath = CONFIG_DIR / f"halt_cot_config_{name}.json"
            config.save_to_file(filepath)
            print(f"ğŸ“„ å·²åˆ›å»ºé…ç½®æ¨¡æ¿: {name}")
        
        return templates
    
    @staticmethod
    def load_config(config_name: str = "default") -> HaltCoTConfig:
        """åŠ è½½æŒ‡å®šé…ç½®"""
        if config_name == "default":
            filepath = CONFIG_DIR / "halt_cot_config.json"
        else:
            filepath = CONFIG_DIR / f"halt_cot_config_{config_name}.json"
        
        if not filepath.exists():
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            print("ğŸ”§ ä½¿ç”¨é»˜è®¤é…ç½®")
            return ConfigTemplates.default_config()
        
        try:
            config = HaltCoTConfig.load_from_file(filepath)
            print(f"âœ… å·²åŠ è½½é…ç½®: {filepath}")
            
            # éªŒè¯é…ç½®
            warnings = ConfigValidator.validate_config(config)
            if warnings:
                print("âš ï¸ é…ç½®éªŒè¯è­¦å‘Š:")
                for warning in warnings:
                    print(f"   {warning}")
            
            return config
            
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
            print("ğŸ”§ ä½¿ç”¨é»˜è®¤é…ç½®")
            return ConfigTemplates.default_config()

# ============================================================================
# å…¼å®¹æ€§é€‚é…å™¨
# ============================================================================
class LegacyConfigAdapter:
    """ç”¨äºé€‚é…åŸå§‹ä»£ç çš„é…ç½®æ ¼å¼"""
    
    @staticmethod
    def to_legacy_format(config: HaltCoTConfig) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºåŸå§‹ä»£ç æœŸæœ›çš„é…ç½®æ ¼å¼"""
        return {
            "model_name": config.model.name,
            "data_path": config.data.data_path,
            "sample_size": config.data.sample_size,
            "cooldown": config.probe.cooldown,
            "max_tokens": config.generation.max_tokens,
            "debug": config.experiment.debug
        }

# ============================================================================
# Main - ç”Ÿæˆé…ç½®æ–‡ä»¶
# ============================================================================
if __name__ == "__main__":
    print("ğŸ”§ HALT-CoT é…ç½®æ–‡ä»¶ç”Ÿæˆå™¨")
    print("=" * 50)
    
    # åˆ›å»ºæ‰€æœ‰æ¨¡æ¿é…ç½®
    ConfigManager.create_all_template_configs()
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    config = ConfigTemplates.default_config()
    print(f"\nğŸ“‹ é»˜è®¤é…ç½®æ¦‚è§ˆ:")
    print(f"   æ¨¡å‹: {config.model.name}")
    print(f"   æ•°æ®: {config.data.sample_size} ä¸ªæ ·æœ¬")
    print(f"   æœ€å¤§tokens: {config.generation.max_tokens}")
    print(f"   æ¢æµ‹é—´éš”: {config.probe.cooldown}")
    print(f"   ç»“æœç›®å½•: {config.output.results_dir}")
    
    print(f"\nğŸ“ é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {CONFIG_DIR}")
    print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print("   from config import ConfigManager")
    print("   config = ConfigManager.load_config('default')")
    print("   legacy_config = LegacyConfigAdapter.to_legacy_format(config)")
