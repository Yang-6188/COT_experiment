"""ç»Ÿè®¡è®¡ç®—å™¨"""
from typing import Dict, Any, List
from collections import Counter


class StatisticsCalculator:
    """
    ç»Ÿè®¡è®¡ç®—å™¨
    è´Ÿè´£è®¡ç®—å’Œå±•ç¤ºå®éªŒç»Ÿè®¡ä¿¡æ¯
    """
    
    def calculate(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            results: å®éªŒç»“æœåˆ—è¡¨
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not results:
            return {}
        
        total_samples = len(results)
        correct_samples = sum(1 for r in results if r['correct'])
        total_time = sum(r['generation_time'] for r in results)
        total_tokens = sum(r['tokens_used'] for r in results)
        early_stops = sum(1 for r in results if r.get('early_stopped', False))
        
        halt_reasons = Counter(r.get('halt_reason') for r in results if r.get('early_stopped', False))
        avg_entropy = sum(r.get('avg_entropy', 0) for r in results) / total_samples
        token_counts = [r['tokens_used'] for r in results]
        
        # é˜¶æ®µæ£€æµ‹æ¨¡å¼ç»Ÿè®¡
        stage_modes = Counter(r.get('stage_detection_mode', 'unknown') for r in results)
        
        # æ£€æŸ¥ç‚¹ç»Ÿè®¡
        total_checkpoints = sum(
            r.get('checkpoint_stats', {}).get('total_checks', 0) 
            for r in results
        )
        
        return {
            "total_samples": total_samples,
            "correct_samples": correct_samples,
            "accuracy": correct_samples / total_samples,
            "total_time": total_time,
            "avg_time_per_sample": total_time / total_samples,
            "total_tokens": total_tokens,
            "avg_tokens_per_sample": total_tokens / total_samples,
            "min_tokens": min(token_counts) if token_counts else 0,
            "max_tokens": max(token_counts) if token_counts else 0,
            "early_stops": early_stops,
            "early_stop_rate": early_stops / total_samples,
            "halt_reasons": dict(halt_reasons),
            "avg_entropy": avg_entropy,
            "stage_detection_modes": dict(stage_modes),
            "total_checkpoints": total_checkpoints,
            "avg_checkpoints_per_sample": total_checkpoints / total_samples if total_samples > 0 else 0
        }
    
    def print_statistics(self, stats: Dict[str, Any], config: dict):
        """
        æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            stats: ç»Ÿè®¡ä¿¡æ¯
            config: é…ç½®ä¿¡æ¯
        """
        print("\n" + "=" * 60)
        print("ğŸ“Š HALT-CoT å®éªŒç»Ÿè®¡ç»“æœ")
        print("=" * 60)
        print(f"ğŸ¤– æ¨¡å‹: {config['model_configs'][config['active_model']]['name']}")
        print(f"ğŸ“ æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
        print(f"âœ… æ­£ç¡®æ ·æœ¬: {stats['correct_samples']}")
        print(f"ğŸ¯ å‡†ç¡®ç‡: {stats['accuracy']:.2%}")
        print(f"ğŸ›‘ æ—©åœç‡: {stats['early_stop_rate']:.2%} ({stats['early_stops']}/{stats['total_samples']})")
        print(f"â±ï¸  å¹³å‡ç”¨æ—¶: {stats['avg_time_per_sample']:.1f}ç§’/æ ·æœ¬")
        print(f"ğŸ’¬ å¹³å‡Token: {stats['avg_tokens_per_sample']:.1f}ä¸ª/æ ·æœ¬")
        print(f"ğŸ“Š TokenèŒƒå›´: {stats['min_tokens']} - {stats['max_tokens']}")
        print(f"ğŸ“‰ å¹³å‡ç†µ: {stats['avg_entropy']:.3f}")
        print(f"ğŸ” å¹³å‡æ£€æŸ¥ç‚¹: {stats['avg_checkpoints_per_sample']:.1f}æ¬¡/æ ·æœ¬")
        print(f"ğŸ• æ€»ç”¨æ—¶: {stats['total_time']//60:.0f}åˆ†{stats['total_time']%60:.0f}ç§’")
        
        # é˜¶æ®µæ£€æµ‹æ¨¡å¼ä¿¡æ¯
        stage_config = config.get('stage_control', {})
        use_smart = stage_config.get('use_smart_detection', True)
        stage_mode = "æ™ºèƒ½æ£€æµ‹" if use_smart else "å¥å­è¾¹ç•Œæ£€æµ‹"
        print(f"ğŸ” æ£€æµ‹æ¨¡å¼: {stage_mode}")
        
        if stats.get('halt_reasons'):
            print("\nğŸ” æ—©åœåŸå› åˆ†å¸ƒ:")
            for reason, count in stats['halt_reasons'].items():
                if reason:
                    print(f"   - {reason}: {count}æ¬¡")
        
        print("=" * 60)
