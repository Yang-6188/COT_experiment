#!/usr/bin/env python3
"""
HALT-CoTé…ç½®å·¥å…· - æ”¯æŒå¤šæ•°æ®é›†
æ”¯æŒæ‰¹é‡å¿«é€Ÿä¿®æ”¹å‚æ•°ï¼ŒåŒ…æ‹¬æ—©åœç­–ç•¥å’Œè°ƒè¯•æ¢é’ˆ
æ”¯æŒ GSM8K å’Œ MATH æ•°æ®é›†åˆ‡æ¢
"""

import json
import os
from pathlib import Path

BASE_DIR = Path("/root/autodl-tmp")
CONFIG_DIR = BASE_DIR / "config"
DATA_DIR = BASE_DIR / "data"

def ensure_directories():
    """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
    try:
        CONFIG_DIR.mkdir(parents=True, exist_ok=True)
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        (BASE_DIR / "results").mkdir(parents=True, exist_ok=True)
    except Exception as e:
        print(f"âŒ åˆ›å»ºç›®å½•æ—¶å‡ºé”™: {e}")
        raise

def detect_available_datasets():
    """æ£€æµ‹å¯ç”¨çš„æ•°æ®é›†"""
    available = {}
    
    # æ£€æµ‹ GSM8K
    gsm8k_files = {
        'test': DATA_DIR / "gsm8k_test.json",
        'test_processed': DATA_DIR / "gsm8k_test_processed.json",
        'sample_5': DATA_DIR / "gsm8k_test_sample_5.json",
        'sample_10': DATA_DIR / "gsm8k_test_sample_10.json",
        'sample_20': DATA_DIR / "gsm8k_test_sample_20.json",
        'sample_50': DATA_DIR / "gsm8k_test_sample_50.json",
        'sample_100': DATA_DIR / "gsm8k_test_sample_100.json",
    }
    
    gsm8k_available = any(f.exists() for f in gsm8k_files.values())
    if gsm8k_available:
        available['gsm8k'] = {
            'name': 'GSM8K',
            'description': 'å°å­¦æ•°å­¦åº”ç”¨é¢˜',
            'files': {k: str(v) for k, v in gsm8k_files.items() if v.exists()}
        }
    
    # æ£€æµ‹ MATH
    math_files = {
        'test': DATA_DIR / "math_test.json",
        'test_processed': DATA_DIR / "math_test_processed.json",
        'sample_5': DATA_DIR / "math_test_sample_5.json",
        'sample_10': DATA_DIR / "math_test_sample_10.json",
        'sample_20': DATA_DIR / "math_test_sample_20.json",
        'sample_50': DATA_DIR / "math_test_sample_50.json",
        'sample_100': DATA_DIR / "math_test_sample_100.json",
    }
    
    math_available = any(f.exists() for f in math_files.values())
    if math_available:
        # æ£€æµ‹éš¾åº¦çº§åˆ«å­é›†
        level_files = list(DATA_DIR.glob("math_test_level_*.json"))
        type_files = list(DATA_DIR.glob("math_test_type_*.json"))
        
        available['math'] = {
            'name': 'MATH',
            'description': 'ç«èµ›æ•°å­¦é¢˜',
            'files': {k: str(v) for k, v in math_files.items() if v.exists()},
            'level_subsets': [f.name for f in level_files],
            'type_subsets': [f.name for f in type_files]
        }
    
    return available

def create_default_config():
    """åˆ›å»ºä¸å®é™…é…ç½®æ–‡ä»¶åŒ¹é…çš„é»˜è®¤é…ç½®"""
    available_datasets = detect_available_datasets()
    
    # é»˜è®¤ä½¿ç”¨ GSM8Kï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ MATH
    default_dataset = 'gsm8k' if 'gsm8k' in available_datasets else 'math'
    default_test_file = f"data/{default_dataset}_test.json"
    
    config = {
        "active_model": "qwen",
        "active_dataset": default_dataset,  # æ–°å¢ï¼šå½“å‰ä½¿ç”¨çš„æ•°æ®é›†
        "model_configs": {
            "qwen": {
                "name": "Qwen/Qwen2.5-7B-Instruct"
            },
            "qwen-3b": {
                "name": "Qwen/Qwen2.5-3B-Instruct"
            },
            "qwen-14b": {
                "name": "Qwen/Qwen2.5-14B-Instruct"
            }
        },
        "dataset_configs": {  # æ–°å¢ï¼šæ•°æ®é›†é…ç½®
            "gsm8k": {
                "name": "GSM8K",
                "test_file": "data/gsm8k_test.json",
                "test_processed": "data/gsm8k_test_processed.json",
                "description": "å°å­¦æ•°å­¦åº”ç”¨é¢˜"
            },
            "math": {
                "name": "MATH",
                "test_file": "data/math_test.json",
                "test_processed": "data/math_test_processed.json",
                "description": "ç«èµ›æ•°å­¦é¢˜ (Level 1-5)"
            }
        },
        "paths": {
            "test_data": default_test_file,
            "data_dir": "data",
            "results_dir": "results"
        },
        "experiment": {
            "sample_size": 10,
            "max_new_tokens": 512,
            "do_sample": False,
            "temperature": 0.7,
            "save_results": True,
            "verbose": False,
            "debug_probe": True
        },
        "early_stopping": {
            "use_answer_consistency": True,
            "use_entropy_halt": True,
            "consistency_k": 3,
            "entropy_threshold": 0.6,
            "entropy_consecutive_steps": 2,
            "min_tokens_before_check": 100,
            "cooldown_tokens": 40
        }
    }
    return config

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_file = CONFIG_DIR / "config.json"
    
    if not config_file.exists():
        config = create_default_config()
        save_config(config)
        return config
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # æ£€æŸ¥å¹¶å‡çº§é…ç½®ç»“æ„
        default = create_default_config()
        needs_update = False
        
        # æ·»åŠ æ•°æ®é›†é…ç½®
        if 'active_dataset' not in config:
            print("âš ï¸  æ·»åŠ æ•°æ®é›†é…ç½®...")
            config['active_dataset'] = default['active_dataset']
            needs_update = True
        
        if 'dataset_configs' not in config:
            config['dataset_configs'] = default['dataset_configs']
            needs_update = True
        
        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘ early_stopping é…ç½®
        if 'early_stopping' not in config:
            print("âš ï¸  æ£€æµ‹åˆ°ç¼ºå°‘ early_stopping é…ç½®ï¼Œæ­£åœ¨æ·»åŠ ...")
            config['early_stopping'] = default['early_stopping']
            needs_update = True
        else:
            # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘æ–°çš„æ—©åœå‚æ•°
            early_stop = config['early_stopping']
            default_early = default['early_stopping']
            
            for key in ['min_tokens_before_check', 'cooldown_tokens']:
                if key not in early_stop:
                    print(f"âš ï¸  æ·»åŠ æ–°çš„æ—©åœå‚æ•°: {key}")
                    early_stop[key] = default_early[key]
                    needs_update = True
            
            # ç§»é™¤å·²åºŸå¼ƒçš„å‚æ•°
            if 'chunk_by_sentence' in early_stop:
                print("âš ï¸  ç§»é™¤å·²åºŸå¼ƒçš„å‚æ•°: chunk_by_sentence")
                del early_stop['chunk_by_sentence']
                needs_update = True
        
        # æ£€æŸ¥å®éªŒé…ç½®å®Œæ•´æ€§
        if 'experiment' not in config:
            print("âš ï¸  é‡å»ºå®éªŒé…ç½®...")
            config['experiment'] = default['experiment']
            needs_update = True
        else:
            # æ·»åŠ  debug_probe å‚æ•°
            if 'debug_probe' not in config['experiment']:
                print("âš ï¸  æ·»åŠ è°ƒè¯•æ¢é’ˆå‚æ•°: debug_probe")
                config['experiment']['debug_probe'] = default['experiment']['debug_probe']
                needs_update = True
        
        # æ¸…ç†å¤šä½™çš„ metadata
        if 'metadata' in config:
            print("âš ï¸  ç§»é™¤ metadata å­—æ®µï¼ˆç²¾ç®€é…ç½®ï¼‰")
            del config['metadata']
            needs_update = True
        
        if needs_update:
            save_config(config)
            
        return config
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®å‡ºé”™: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
        return create_default_config()

def save_config(config):
    """ä¿å­˜é…ç½®"""
    ensure_directories()
    config_file = CONFIG_DIR / "config.json"
    try:
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        print(f"âœ… é…ç½®å·²ä¿å­˜è‡³: {config_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")

def show_current_config():
    """æ˜¾ç¤ºå½“å‰é…ç½®æ‘˜è¦"""
    config = load_config()
    exp = config['experiment']
    early_stop = config.get('early_stopping', {})
    available_datasets = detect_available_datasets()
    
    print("\nğŸ“‹ å½“å‰é…ç½®çŠ¶æ€")
    print("=" * 60)
    
    # åŸºç¡€é…ç½®
    model_name = config['model_configs'][config['active_model']]['name']
    print(f"ğŸ¤– æ¨¡å‹:         {config['active_model']} ({model_name})")
    
    # æ•°æ®é›†ä¿¡æ¯
    active_dataset = config.get('active_dataset', 'gsm8k')
    dataset_info = config.get('dataset_configs', {}).get(active_dataset, {})
    print(f"ğŸ“š æ•°æ®é›†:       {active_dataset.upper()} - {dataset_info.get('description', '')}")
    
    # æ˜¾ç¤ºå¯ç”¨æ•°æ®é›†
    if len(available_datasets) > 1:
        other_datasets = [d for d in available_datasets.keys() if d != active_dataset]
        print(f"   å¯åˆ‡æ¢è‡³:     {', '.join([d.upper() for d in other_datasets])}")
    
    print(f"ğŸ“Š æ ·æœ¬æ•°é‡:     {exp['sample_size']}")
    print(f"ğŸ“ æœ€å¤§ç”Ÿæˆ:     {exp['max_new_tokens']} tokens")
    print(f"ğŸŒ¡ï¸ æ¸©åº¦:         {exp['temperature']}")
    print(f"ğŸ² éšæœºé‡‡æ ·:     {'å¼€å¯' if exp['do_sample'] else 'å…³é—­'}")
    print(f"ğŸ“ è¯¦ç»†è¾“å‡º:     {'å¼€å¯' if exp['verbose'] else 'å…³é—­'}")
    print(f"ğŸ” è°ƒè¯•æ¢é’ˆ:     {'å¼€å¯' if exp.get('debug_probe', True) else 'å…³é—­'}")
    print(f"ğŸ’¾ ä¿å­˜ç»“æœ:     {'å¼€å¯' if exp['save_results'] else 'å…³é—­'}")
    
    print(f"\nğŸ›‘ æ—©åœç­–ç•¥é…ç½®")
    print("-" * 60)
    print(f"âœ… ç­”æ¡ˆä¸€è‡´æ€§:   {'å¼€å¯' if early_stop.get('use_answer_consistency') else 'å…³é—­'}")
    print(f"ğŸ“‰ ç†µæ£€æµ‹:       {'å¼€å¯' if early_stop.get('use_entropy_halt') else 'å…³é—­'}")
    
    if early_stop.get('use_answer_consistency'):
        print(f"ğŸ” ä¸€è‡´æ€§Kå€¼:    {early_stop.get('consistency_k', 3)} æ¬¡ç›¸åŒç­”æ¡ˆè§¦å‘")
    
    if early_stop.get('use_entropy_halt'):
        print(f"ğŸ“Š ç†µé˜ˆå€¼:       {early_stop.get('entropy_threshold', 0.6)}")
        print(f"ğŸ”„ è¿ç»­ä½ç†µæ­¥æ•°: {early_stop.get('entropy_consecutive_steps', 2)}")
    
    print(f"\nâš™ï¸ æ£€æŸ¥ç‚¹æ§åˆ¶")
    print("-" * 60)
    print(f"ğŸš¦ æœ€å°æ£€æŸ¥é—´éš”: {early_stop.get('min_tokens_before_check', 100)} tokens")
    print(f"â„ï¸ å†·å´é—´éš”:     {early_stop.get('cooldown_tokens', 40)} tokens")
    
    print("=" * 60)
    return config

def switch_dataset():
    """åˆ‡æ¢æ•°æ®é›†"""
    config = load_config()
    available_datasets = detect_available_datasets()
    
    if not available_datasets:
        print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•å¯ç”¨æ•°æ®é›†ï¼")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬ä¸‹è½½æ•°æ®é›†")
        return
    
    print("\nğŸ“š åˆ‡æ¢æ•°æ®é›†")
    print("=" * 60)
    print("å¯ç”¨æ•°æ®é›†:")
    
    dataset_list = []
    for i, (key, info) in enumerate(available_datasets.items(), 1):
        current = "ğŸ‘ˆ [å½“å‰]" if key == config.get('active_dataset') else ""
        print(f"{i}. {info['name']:10s} - {info['description']} {current}")
        dataset_list.append(key)
        
        # æ˜¾ç¤ºå¯ç”¨æ–‡ä»¶
        if 'sample_5' in info['files']:
            print(f"   âœ… åŒ…å«é‡‡æ ·æ•°æ®é›† (5, 10, 20, 50, 100 æ ·æœ¬)")
        
        # MATH æ•°æ®é›†çš„é¢å¤–ä¿¡æ¯
        if key == 'math' and 'level_subsets' in info:
            print(f"   âœ… åŒ…å« {len(info['level_subsets'])} ä¸ªéš¾åº¦å­é›†")
            print(f"   âœ… åŒ…å« {len(info['type_subsets'])} ä¸ªç±»åˆ«å­é›†")
    
    print("0. å–æ¶ˆ")
    print("=" * 60)
    
    choice = input("\nè¯·é€‰æ‹©æ•°æ®é›† (0-{}): ".format(len(dataset_list))).strip()
    
    try:
        choice_num = int(choice)
        if choice_num == 0:
            print("å·²å–æ¶ˆ")
            return
        
        if 1 <= choice_num <= len(dataset_list):
            selected_dataset = dataset_list[choice_num - 1]
            
            # æ›´æ–°é…ç½®
            config['active_dataset'] = selected_dataset
            dataset_config = config['dataset_configs'][selected_dataset]
            config['paths']['test_data'] = dataset_config['test_file']
            
            save_config(config)
            print(f"\nâœ… å·²åˆ‡æ¢åˆ°æ•°æ®é›†: {selected_dataset.upper()}")
            
            # å¦‚æœæ˜¯ MATH æ•°æ®é›†ï¼Œè¯¢é—®æ˜¯å¦ä½¿ç”¨å­é›†
            if selected_dataset == 'math':
                use_subset = input("\næ˜¯å¦ä½¿ç”¨ç‰¹å®šå­é›†ï¼Ÿ(y/n): ").strip().lower()
                if use_subset == 'y':
                    select_math_subset(config)
            
            show_current_config()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
    except ValueError:
        print("âŒ è¯·è¾“å…¥æ•°å­—")

def select_math_subset():
    """é€‰æ‹© MATH æ•°æ®é›†çš„å­é›†"""
    print("\nğŸ“Š é€‰æ‹© MATH å­é›†ç±»å‹")
    print("=" * 60)
    print("1. æŒ‰éš¾åº¦é€‰æ‹© (Level 1-5)")
    print("2. æŒ‰ç±»åˆ«é€‰æ‹© (ä»£æ•°ã€å‡ ä½•ç­‰)")
    print("3. ä½¿ç”¨å®Œæ•´æµ‹è¯•é›†")
    print("0. å–æ¶ˆ")
    
    choice = input("\nè¯·é€‰æ‹© (0-3): ").strip()
    
    if choice == '1':
        select_math_level_subset()
    elif choice == '2':
        select_math_type_subset()
    elif choice == '3':
        print("âœ… ä½¿ç”¨å®Œæ•´æµ‹è¯•é›†")
    elif choice == '0':
        print("å·²å–æ¶ˆ")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

def select_math_level_subset():
    """é€‰æ‹© MATH éš¾åº¦å­é›†"""
    level_files = list(DATA_DIR.glob("math_test_level_*.json"))
    
    if not level_files:
        print("âŒ æœªæ‰¾åˆ°éš¾åº¦å­é›†æ–‡ä»¶")
        return
    
    print("\nğŸ“ˆ å¯ç”¨éš¾åº¦çº§åˆ«:")
    print("-" * 40)
    
    levels = []
    for i, f in enumerate(sorted(level_files), 1):
        level_name = f.stem.replace('math_test_level_', '')
        
        # è¯»å–æ–‡ä»¶è·å–é¢˜ç›®æ•°é‡
        try:
            with open(f, 'r') as file:
                data = json.load(file)
                count = len(data)
            print(f"{i}. {level_name:15s} ({count} é¢˜)")
            levels.append((level_name, str(f)))
        except:
            continue
    
    print("0. å–æ¶ˆ")
    
    choice = input(f"\nè¯·é€‰æ‹©éš¾åº¦ (0-{len(levels)}): ").strip()
    
    try:
        choice_num = int(choice)
        if choice_num == 0:
            return
        
        if 1 <= choice_num <= len(levels):
            level_name, file_path = levels[choice_num - 1]
            
            config = load_config()
            config['paths']['test_data'] = file_path
            save_config(config)
            
            print(f"âœ… å·²é€‰æ‹©éš¾åº¦å­é›†: {level_name}")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
    except ValueError:
        print("âŒ è¯·è¾“å…¥æ•°å­—")

def select_math_type_subset():
    """é€‰æ‹© MATH ç±»åˆ«å­é›†"""
    type_files = list(DATA_DIR.glob("math_test_type_*.json"))
    
    if not type_files:
        print("âŒ æœªæ‰¾åˆ°ç±»åˆ«å­é›†æ–‡ä»¶")
        return
    
    print("\nğŸ¯ å¯ç”¨é—®é¢˜ç±»åˆ«:")
    print("-" * 40)
    
    types = []
    for i, f in enumerate(sorted(type_files), 1):
        type_name = f.stem.replace('math_test_type_', '').replace('_', ' ')
        
        # è¯»å–æ–‡ä»¶è·å–é¢˜ç›®æ•°é‡
        try:
            with open(f, 'r') as file:
                data = json.load(file)
                count = len(data)
            print(f"{i}. {type_name:30s} ({count} é¢˜)")
            types.append((type_name, str(f)))
        except:
            continue
    
    print("0. å–æ¶ˆ")
    
    choice = input(f"\nè¯·é€‰æ‹©ç±»åˆ« (0-{len(types)}): ").strip()
    
    try:
        choice_num = int(choice)
        if choice_num == 0:
            return
        
        if 1 <= choice_num <= len(types):
            type_name, file_path = types[choice_num - 1]
            
            config = load_config()
            config['paths']['test_data'] = file_path
            save_config(config)
            
            print(f"âœ… å·²é€‰æ‹©ç±»åˆ«å­é›†: {type_name}")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
    except ValueError:
        print("âŒ è¯·è¾“å…¥æ•°å­—")

def get_input_with_default(prompt, default_val, validator=None, error_msg="è¾“å…¥æ— æ•ˆ"):
    """è·å–è¾“å…¥ï¼Œç›´æ¥å›è½¦åˆ™ä½¿ç”¨é»˜è®¤å€¼"""
    while True:
        user_input = input(f"{prompt} [å½“å‰: {default_val}]: ").strip()
        
        if not user_input:
            return default_val
            
        try:
            if validator:
                validated_val = validator(user_input)
                if validated_val is not None:
                    return validated_val
                else:
                    print(f"âŒ {error_msg}")
            else:
                return user_input
        except Exception:
            print(f"âŒ {error_msg}")

def batch_modify_basic_config():
    """æ‰¹é‡ä¿®æ”¹åŸºç¡€é…ç½®"""
    config = load_config()
    print("\nâœï¸  ä¿®æ”¹åŸºç¡€é…ç½® (ç›´æ¥å›è½¦ = ä¿æŒä¸å˜)")
    print("-" * 50)

    # 1. ä¿®æ”¹æ¨¡å‹
    models = list(config['model_configs'].keys())
    print(f"å¯ç”¨æ¨¡å‹: {', '.join(models)}")
    
    def validate_model(val):
        return val if val in models else None
        
    config['active_model'] = get_input_with_default(
        "ğŸ‘‰ é€‰æ‹©æ¨¡å‹",
        config['active_model'], 
        validate_model,
        f"è¯·è¾“å…¥ä»¥ä¸‹ä¹‹ä¸€: {models}"
    )

    # 2. ä¿®æ”¹æ ·æœ¬æ•°
    def validate_int_range(min_val, max_val):
        def validator(val):
            try:
                v = int(val)
                return v if min_val <= v <= max_val else None
            except: return None
        return validator
        
    config['experiment']['sample_size'] = get_input_with_default(
        "ğŸ‘‰ æ ·æœ¬æ•°é‡ (1-1000)",
        config['experiment']['sample_size'],
        validate_int_range(1, 1000),
        "è¯·è¾“å…¥ 1-1000 çš„æ•´æ•°"
    )

    # 3. ä¿®æ”¹æœ€å¤§ç”Ÿæˆé•¿åº¦
    config['experiment']['max_new_tokens'] = get_input_with_default(
        "ğŸ‘‰ æœ€å¤§ç”Ÿæˆtokens (128-2048)",
        config['experiment']['max_new_tokens'],
        validate_int_range(128, 2048),
        "è¯·è¾“å…¥ 128-2048 çš„æ•´æ•°"
    )

    # 4. ä¿®æ”¹æ¸©åº¦
    def validate_float_range(min_val, max_val):
        def validator(val):
            try:
                v = float(val)
                return v if min_val <= v <= max_val else None
            except: return None
        return validator

    config['experiment']['temperature'] = get_input_with_default(
        "ğŸ‘‰ æ¸©åº¦ (0.0-2.0)",
        config['experiment']['temperature'],
        validate_float_range(0.0, 2.0),
        "è¯·è¾“å…¥ 0.0-2.0 çš„æ•°å­—"
    )

    # 5. ä¿®æ”¹é‡‡æ ·æ¨¡å¼
    def validate_bool(val):
        v = val.lower()
        if v in ['y', 'yes', 'true', '1']: return True
        if v in ['n', 'no', 'false', '0']: return False
        return None

    config['experiment']['do_sample'] = get_input_with_default(
        "ğŸ‘‰ å¯ç”¨éšæœºé‡‡æ · (y/n)",
        config['experiment']['do_sample'],
        validate_bool,
        "è¯·è¾“å…¥ y æˆ– n"
    )

    # 6. è¯¦ç»†è¾“å‡º
    config['experiment']['verbose'] = get_input_with_default(
        "ğŸ‘‰ æ˜¾ç¤ºè¯¦ç»†è¾“å‡º (y/n)",
        config['experiment']['verbose'],
        validate_bool,
        "è¯·è¾“å…¥ y æˆ– n"
    )

    # 7. è°ƒè¯•æ¢é’ˆ
    config['experiment']['debug_probe'] = get_input_with_default(
        "ğŸ‘‰ å¯ç”¨è°ƒè¯•æ¢é’ˆ (y/n)",
        config['experiment'].get('debug_probe', True),
        validate_bool,
        "è¯·è¾“å…¥ y æˆ– n"
    )

    print("-" * 50)
    save_config(config)
    print("\nâœ¨ åŸºç¡€é…ç½®å·²æ›´æ–°ï¼")

def modify_early_stopping():
    """ä¿®æ”¹æ—©åœç­–ç•¥é…ç½®"""
    config = load_config()
    early_stop = config.get('early_stopping', {})
    
    print("\nğŸ›‘ ä¿®æ”¹æ—©åœç­–ç•¥é…ç½® (ç›´æ¥å›è½¦ = ä¿æŒä¸å˜)")
    print("-" * 50)
    
    def validate_bool(val):
        v = val.lower()
        if v in ['y', 'yes', 'true', '1']: return True
        if v in ['n', 'no', 'false', '0']: return False
        return None
    
    def validate_int_range(min_val, max_val):
        def validator(val):
            try:
                v = int(val)
                return v if min_val <= v <= max_val else None
            except: return None
        return validator
    
    def validate_float_range(min_val, max_val):
        def validator(val):
            try:
                v = float(val)
                return v if min_val <= v <= max_val else None
            except: return None
        return validator
    
    # 1. ç­”æ¡ˆä¸€è‡´æ€§å¼€å…³
    early_stop['use_answer_consistency'] = get_input_with_default(
        "ğŸ‘‰ å¯ç”¨ç­”æ¡ˆä¸€è‡´æ€§æ£€æµ‹ (y/n)",
        early_stop.get('use_answer_consistency', True),
        validate_bool,
        "è¯·è¾“å…¥ y æˆ– n"
    )
    
    # 2. ä¸€è‡´æ€§Kå€¼
    if early_stop['use_answer_consistency']:
        early_stop['consistency_k'] = get_input_with_default(
            "ğŸ‘‰ ç­”æ¡ˆä¸€è‡´æ€§Kå€¼ (2-10)",
            early_stop.get('consistency_k', 3),
            validate_int_range(2, 10),
            "è¯·è¾“å…¥ 2-10 çš„æ•´æ•°"
        )
    
    # 3. ç†µæ£€æµ‹å¼€å…³
    early_stop['use_entropy_halt'] = get_input_with_default(
        "ğŸ‘‰ å¯ç”¨ç†µæ£€æµ‹ (y/n)",
        early_stop.get('use_entropy_halt', True),
        validate_bool,
        "è¯·è¾“å…¥ y æˆ– n"
    )
    
    # 4. ç†µç›¸å…³å‚æ•°
    if early_stop['use_entropy_halt']:
        early_stop['entropy_threshold'] = get_input_with_default(
            "ğŸ‘‰ ç†µé˜ˆå€¼ (0.1-2.0, è¶Šå°è¶Šä¸¥æ ¼)",
            early_stop.get('entropy_threshold', 0.6),
            validate_float_range(0.1, 2.0),
            "è¯·è¾“å…¥ 0.1-2.0 çš„æ•°å­—"
        )
        
        early_stop['entropy_consecutive_steps'] = get_input_with_default(
            "ğŸ‘‰ è¿ç»­ä½ç†µæ­¥æ•° (1-5)",
            early_stop.get('entropy_consecutive_steps', 2),
            validate_int_range(1, 5),
            "è¯·è¾“å…¥ 1-5 çš„æ•´æ•°"
        )
    
    # 5. æ£€æŸ¥ç‚¹æ§åˆ¶å‚æ•°
    print(f"\nâš™ï¸ æ£€æŸ¥ç‚¹æ§åˆ¶å‚æ•°")
    print("-" * 30)
    
    early_stop['min_tokens_before_check'] = get_input_with_default(
        "ğŸ‘‰ æœ€å°æ£€æŸ¥é—´éš” (50-200 tokens)",
        early_stop.get('min_tokens_before_check', 100),
        validate_int_range(50, 200),
        "è¯·è¾“å…¥ 50-200 çš„æ•´æ•°"
    )
    
    early_stop['cooldown_tokens'] = get_input_with_default(
        "ğŸ‘‰ å†·å´é—´éš” (20-100 tokens)",
        early_stop.get('cooldown_tokens', 40),
        validate_int_range(20, 100),
        "è¯·è¾“å…¥ 20-100 çš„æ•´æ•°"
    )
    
    config['early_stopping'] = early_stop
    
    print("-" * 50)
    save_config(config)
    print("\nâœ¨ æ—©åœç­–ç•¥é…ç½®å·²æ›´æ–°ï¼")

def create_preset_configs():
    """åˆ›å»ºé¢„è®¾é…ç½®"""
    base_config = create_default_config()
    presets = {}
    
    # å¿«é€Ÿæµ‹è¯•é¢„è®¾ - GSM8K
    presets['quick_test_gsm8k'] = {
        'active_model': 'qwen-3b',
        'active_dataset': 'gsm8k',
        'model_configs': base_config['model_configs'],
        'dataset_configs': base_config['dataset_configs'],
        'paths': {
            'test_data': 'data/gsm8k_test_sample_5.json',
            'data_dir': 'data',
            'results_dir': 'results'
        },
        'experiment': {
            'sample_size': 5,
            'max_new_tokens': 256,
            'do_sample': False,
            'temperature': 0.0,
            'save_results': True,
            'verbose': True,
            'debug_probe': True
        },
        'early_stopping': {
            'use_answer_consistency': True,
            'use_entropy_halt': True,
            'consistency_k': 2,
            'entropy_threshold': 0.8,
            'entropy_consecutive_steps': 1,
            'min_tokens_before_check': 50,
            'cooldown_tokens': 20
        }
    }
    
    # å¿«é€Ÿæµ‹è¯•é¢„è®¾ - MATH
    presets['quick_test_math'] = {
        'active_model': 'qwen-3b',
        'active_dataset': 'math',
        'model_configs': base_config['model_configs'],
        'dataset_configs': base_config['dataset_configs'],
        'paths': {
            'test_data': 'data/math_test_sample_5.json',
            'data_dir': 'data',
            'results_dir': 'results'
        },
        'experiment': {
            'sample_size': 5,
            'max_new_tokens': 512,  # MATH éœ€è¦æ›´é•¿çš„ç”Ÿæˆ
            'do_sample': False,
            'temperature': 0.0,
            'save_results': True,
            'verbose': True,
            'debug_probe': True
        },
        'early_stopping': {
            'use_answer_consistency': True,
            'use_entropy_halt': True,
            'consistency_k': 2,
            'entropy_threshold': 0.7,
            'entropy_consecutive_steps': 2,
            'min_tokens_before_check': 80,
            'cooldown_tokens': 30
        }
    }
    
    # æ ‡å‡†å®éªŒé¢„è®¾ - GSM8K
    presets['standard_gsm8k'] = {
        'active_model': 'qwen',
        'active_dataset': 'gsm8k',
        'model_configs': base_config['model_configs'],
        'dataset_configs': base_config['dataset_configs'],
        'paths': {
            'test_data': 'data/gsm8k_test.json',
            'data_dir': 'data',
            'results_dir': 'results'
        },
        'experiment': {
            'sample_size': 50,
            'max_new_tokens': 512,
            'do_sample': False,
            'temperature': 0.0,
            'save_results': True,
            'verbose': False,
            'debug_probe': False
        },
        'early_stopping': base_config['early_stopping']
    }
    
    # æ ‡å‡†å®éªŒé¢„è®¾ - MATH
    presets['standard_math'] = {
        'active_model': 'qwen',
        'active_dataset': 'math',
        'model_configs': base_config['model_configs'],
        'dataset_configs': base_config['dataset_configs'],
        'paths': {
            'test_data': 'data/math_test.json',
            'data_dir': 'data',
            'results_dir': 'results'
        },
        'experiment': {
            'sample_size': 50,
            'max_new_tokens': 800,  # MATH éœ€è¦æ›´é•¿
            'do_sample': False,
            'temperature': 0.0,
            'save_results': True,
            'verbose': False,
            'debug_probe': False
        },
        'early_stopping': {
            'use_answer_consistency': True,
            'use_entropy_halt': True,
            'consistency_k': 3,
            'entropy_threshold': 0.5,  # MATH æ›´ä¸¥æ ¼
            'entropy_consecutive_steps': 3,
            'min_tokens_before_check': 120,
            'cooldown_tokens': 50
        }
    }
    
    # é«˜ç²¾åº¦é¢„è®¾ - MATH (ç«èµ›é¢˜)
    presets['high_precision_math'] = {
        'active_model': 'qwen-14b',
        'active_dataset': 'math',
        'model_configs': base_config['model_configs'],
        'dataset_configs': base_config['dataset_configs'],
        'paths': {
            'test_data': 'data/math_test.json',
            'data_dir': 'data',
            'results_dir': 'results'
        },
        'experiment': {
            'sample_size': 100,
            'max_new_tokens': 1024,
            'do_sample': False,
            'temperature': 0.0,
            'save_results': True,
            'verbose': False,
            'debug_probe': False
        },
        'early_stopping': {
            'use_answer_consistency': True,
            'use_entropy_halt': True,
            'consistency_k': 4,
            'entropy_threshold': 0.4,
            'entropy_consecutive_steps': 3,
            'min_tokens_before_check': 150,
            'cooldown_tokens': 60
        }
    }
    
    return presets

def apply_preset():
    """åº”ç”¨é¢„è®¾é…ç½®"""
    presets = create_preset_configs()
    available_datasets = detect_available_datasets()
    
    print("\nğŸ›ï¸  å¯ç”¨é¢„è®¾é…ç½®:")
    print("=" * 60)
    
    preset_list = []
    i = 1
    
    # GSM8K é¢„è®¾
    if 'gsm8k' in available_datasets:
        print("\nğŸ“š GSM8K æ•°æ®é›†é¢„è®¾:")
        print(f"{i}. quick_test_gsm8k  - å¿«é€Ÿæµ‹è¯• (5æ ·æœ¬, 3Bæ¨¡å‹)")
        preset_list.append('quick_test_gsm8k')
        i += 1
        
        print(f"{i}. standard_gsm8k    - æ ‡å‡†å®éªŒ (50æ ·æœ¬, 7Bæ¨¡å‹)")
        preset_list.append('standard_gsm8k')
        i += 1
    
    # MATH é¢„è®¾
    if 'math' in available_datasets:
        print("\nğŸ“ MATH æ•°æ®é›†é¢„è®¾:")
        print(f"{i}. quick_test_math   - å¿«é€Ÿæµ‹è¯• (5æ ·æœ¬, 3Bæ¨¡å‹)")
        preset_list.append('quick_test_math')
        i += 1
        
        print(f"{i}. standard_math     - æ ‡å‡†å®éªŒ (50æ ·æœ¬, 7Bæ¨¡å‹)")
        preset_list.append('standard_math')
        i += 1
        
        print(f"{i}. high_precision_math - é«˜ç²¾åº¦ (100æ ·æœ¬, 14Bæ¨¡å‹)")
        preset_list.append('high_precision_math')
        i += 1
    
    print("\n0. å–æ¶ˆ")
    print("=" * 60)
    
    choice = input(f"\nè¯·é€‰æ‹©é¢„è®¾ (0-{len(preset_list)}): ").strip()
    
    try:
        choice_num = int(choice)
        if choice_num == 0:
            print("å·²å–æ¶ˆ")
            return
        
        if 1 <= choice_num <= len(preset_list):
            preset_name = preset_list[choice_num - 1]
            config = presets[preset_name]
            
            save_config(config)
            print(f"\nâœ… å·²åº”ç”¨é¢„è®¾: {preset_name}")
            show_current_config()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
    except ValueError:
        print("âŒ è¯·è¾“å…¥æ•°å­—")

def main():
    """ä¸»å…¥å£"""
    ensure_directories()
    
    # æ£€æµ‹å¯ç”¨æ•°æ®é›†
    available_datasets = detect_available_datasets()
    
    if not available_datasets:
        print("\nâš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°ä»»ä½•æ•°æ®é›†ï¼")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬:")
        print("   python data_preparation.py --dataset both")
        print()
    
    while True:
        print("\nğŸ”§ HALT-CoT é…ç½®å·¥å…·")
        print("1. æŸ¥çœ‹å½“å‰é…ç½®")
        print("2. åˆ‡æ¢æ•°æ®é›†")
        print("3. ä¿®æ”¹åŸºç¡€é…ç½®")
        print("4. ä¿®æ”¹æ—©åœç­–ç•¥")
        print("5. åº”ç”¨é¢„è®¾é…ç½®")
        print("6. æ¢å¤é»˜è®¤è®¾ç½®")
        print("0. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹© (0-6): ").strip()
        
        if choice == "1":
            show_current_config()
        elif choice == "2":
            switch_dataset()
        elif choice == "3":
            batch_modify_basic_config()
            show_current_config()
        elif choice == "4":
            modify_early_stopping()
            show_current_config()
        elif choice == "5":
            apply_preset()
        elif choice == "6":
            confirm = input("âš ï¸  ç¡®å®šè¦é‡ç½®æ‰€æœ‰é…ç½®ä¸ºé»˜è®¤å€¼å—ï¼Ÿ(y/n): ")
            if confirm.lower() == 'y':
                config = create_default_config()
                save_config(config)
                print("âœ… å·²æ¢å¤é»˜è®¤é…ç½®")
                show_current_config()
        elif choice == "0":
            print("ğŸ‘‹ å†è§ï¼")
            break
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    main()
