#!/usr/bin/env python3
"""
é…ç½®ç®¡ç†å™¨ - äº¤äº’å¼èœå•ç³»ç»Ÿ
æ”¯æŒé€‰æ‹©æ•°æ®é›†å¹¶é€é¡¹ä¿®æ”¹å‚æ•°
"""

import json
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime
import shutil


class InteractiveConfigManager:
    """äº¤äº’å¼é…ç½®ç®¡ç†å™¨"""
    
    # æ•°æ®é›†é…ç½®
    DATASETS = {
        "gsm8k": {
            "gsm8k_5": {"name": "GSM8K (5æ ·æœ¬)", "file": "gsm8k_test_sample_5.json", "size": 5},
            "gsm8k_50": {"name": "GSM8K (50æ ·æœ¬)", "file": "gsm8k_test_sample_50.json", "size": 50},
            "gsm8k_full": {"name": "GSM8K (å®Œæ•´)", "file": "gsm8k_test.json", "size": 1319},
        },
        "math": {
            "math_l1": {"name": "MATH Level 1", "file": "math_test_level_Level_1.json", "size": 50},
            "math_l3": {"name": "MATH Level 3", "file": "math_test_level_Level_3.json", "size": 50},
            "math_l5": {"name": "MATH Level 5", "file": "math_test_level_Level_5.json", "size": 50},
        }
    }
    
    # æ¨¡å‹é…ç½®
    MODELS = {
        "qwen2.5-1.5b": {"name": "Qwen/Qwen2.5-1.5B-Instruct", "desc": "è½»é‡çº§"},
        "qwen2.5-3b": {"name": "Qwen/Qwen2.5-3B-Instruct", "desc": "å¹³è¡¡æ€§èƒ½"},
        "qwen2.5-7b": {"name": "Qwen/Qwen2.5-7B-Instruct", "desc": "é«˜æ€§èƒ½"},
        "qwen2.5-14b": {"name": "Qwen/Qwen2.5-14B-Instruct", "desc": "æœ€é«˜æ€§èƒ½"},
    }
    
    # é»˜è®¤é…ç½®ï¼ˆç®€åŒ–ç‰ˆï¼‰
    DEFAULT_CONFIG = {
        # æ¨¡å‹
        "active_model": "qwen2.5-7b",
        
        # æ•°æ®é›†
        "data": "gsm8k_test_sample_5.json",
        "sample_size": 5,
        
        # ç”Ÿæˆå‚æ•°
        "max_tokens": 512,
        "temperature": 0.0,
        "do_sample": False,
        
        # è¾“å‡ºæ§åˆ¶
        "verbose": False,
        "debug": False,
        "save_results": True,
        
        # æ£€æµ‹æ¨¡å¼
        "use_smart_detection": False,
        "use_sentence_detection": True,
        
        # æ—©åœå‚æ•°
        "use_answer_consistency": True,
        "use_entropy_halt": True,
        "consistency_k": 3,
        "entropy_threshold": 1.0,
        "entropy_steps": 2,
        
        # æ£€æŸ¥ç‚¹å‚æ•°
        "min_tokens": 100,
        "cooldown": 40,
        
        # å¥å­æ£€æµ‹å‚æ•°
        "check_after_complete_sentence": True,
        
        # æ¢é’ˆå‚æ•°
        "max_probe_tokens": 50,
        "probe_temperature": 0.1
    }
    
    def __init__(self, base_dir: str = "/root/autodl-tmp"):
        self.base_dir = Path(base_dir)
        self.config_dir = self.base_dir / "config"
        self.backup_dir = self.config_dir / "backups"
        self.data_dir = self.base_dir / "data"
        
        self.config_dir.mkdir(parents=True, exist_ok=True)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        self.current_config_path = self.config_dir / "config.json"
        self.current_config = self.load_current_config()
    
    def load_current_config(self) -> Dict[str, Any]:
        """åŠ è½½å½“å‰é…ç½®"""
        if self.current_config_path.exists():
            try:
                with open(self.current_config_path, 'r', encoding='utf-8') as f:
                    full_config = json.load(f)
                    
                    # æå–ç®€åŒ–é…ç½®
                    exp = full_config.get('experiment', {})
                    es = full_config.get('early_stopping', {})
                    sc = full_config.get('stage_control', {})
                    sd = full_config.get('sentence_detection', {})
                    ps = full_config.get('probe_system', {})
                    paths = full_config.get('paths', {})
                    
                    return {
                        # æ¨¡å‹
                        "active_model": full_config.get('active_model', 'qwen2.5-7b'),
                        
                        # æ•°æ®é›†
                        "data": paths.get('test_data', '').replace('data/', ''),
                        "sample_size": exp.get('sample_size', 5),
                        
                        # ç”Ÿæˆå‚æ•°
                        "max_tokens": exp.get('max_new_tokens', 512),
                        "temperature": exp.get('temperature', 0.0),
                        "do_sample": exp.get('do_sample', False),
                        
                        # è¾“å‡ºæ§åˆ¶
                        "verbose": exp.get('verbose', False),
                        "debug": exp.get('debug_probe', False),
                        "save_results": exp.get('save_results', True),
                        
                        # æ£€æµ‹æ¨¡å¼
                        "use_smart_detection": sc.get('use_smart_detection', False),
                        "use_sentence_detection": sd.get('enabled', True),
                        
                        # æ—©åœå‚æ•°
                        "use_answer_consistency": es.get('use_answer_consistency', True),
                        "use_entropy_halt": es.get('use_entropy_halt', True),
                        "consistency_k": es.get('consistency_k', 3),
                        "entropy_threshold": es.get('entropy_threshold', 1.0),
                        "entropy_steps": es.get('entropy_consecutive_steps', 2),
                        
                        # æ£€æŸ¥ç‚¹å‚æ•°
                        "min_tokens": es.get('min_tokens_before_check', 100),
                        "cooldown": es.get('cooldown_tokens', 40),
                        
                        # å¥å­æ£€æµ‹å‚æ•°
                        "check_after_complete_sentence": sd.get('check_after_complete_sentence', True),
                        
                        # æ¢é’ˆå‚æ•°
                        "max_probe_tokens": ps.get('max_probe_tokens', 50),
                        "probe_temperature": ps.get('probe_temperature', 0.1)
                    }
            except Exception as e:
                print(f"âš ï¸ åŠ è½½é…ç½®å¤±è´¥: {e}")
        
        return self.DEFAULT_CONFIG.copy()
    
    def show_header(self, title: str):
        """æ˜¾ç¤ºæ ‡é¢˜"""
        print(f"\n{'='*80}")
        print(f"{title:^80}")
        print(f"{'='*80}\n")
    
    def show_config_summary(self, config: Dict[str, Any], show_title: bool = True):
        """æ˜¾ç¤ºé…ç½®æ‘˜è¦"""
        if show_title:
            print(f"\n{'='*80}")
            print(f"{'å½“å‰é…ç½®':^80}")
            print(f"{'='*80}")
        
        # æ¨¡å‹ä¿¡æ¯
        model_info = self.MODELS.get(config['active_model'], {})
        print(f"  ğŸ¤– æ¨¡å‹: {config['active_model']} ({model_info.get('desc', '')})")
        
        # æ•°æ®é›†ä¿¡æ¯
        print(f"  ğŸ“ æ•°æ®é›†: {config['data']}")
        print(f"  ğŸ“Š æ ·æœ¬æ•°: {config['sample_size']}")
        
        # ç”Ÿæˆå‚æ•°
        print(f"\n  ã€ç”Ÿæˆå‚æ•°ã€‘")
        print(f"  ğŸ”¢ æœ€å¤§tokens: {config['max_tokens']}")
        print(f"  ğŸŒ¡ï¸  æ¸©åº¦: {config['temperature']}")
        print(f"  ğŸ² é‡‡æ ·: {'âœ“' if config['do_sample'] else 'âœ—'}")
        
        # è¾“å‡ºæ§åˆ¶
        print(f"\n  ã€è¾“å‡ºæ§åˆ¶ã€‘")
        print(f"  ğŸ“ è¯¦ç»†è¾“å‡º: {'âœ“' if config['verbose'] else 'âœ—'}")
        print(f"  ğŸ› è°ƒè¯•æ¨¡å¼: {'âœ“' if config['debug'] else 'âœ—'}")
        print(f"  ğŸ’¾ ä¿å­˜ç»“æœ: {'âœ“' if config['save_results'] else 'âœ—'}")
        
        # æ£€æµ‹æ¨¡å¼
        print(f"\n  ã€æ£€æµ‹æ¨¡å¼ã€‘")
        if config['use_smart_detection']:
            print(f"  ğŸ” æ™ºèƒ½é˜¶æ®µæ£€æµ‹: âœ“ å¯ç”¨")
        elif config['use_sentence_detection']:
            print(f"  ğŸ” å¥å­è¾¹ç•Œæ£€æµ‹: âœ“ å¯ç”¨")
        else:
            print(f"  ğŸ” æ£€æµ‹æ¨¡å¼: âœ— ç¦ç”¨")
        
        # æ—©åœæœºåˆ¶
        print(f"\n  ã€æ—©åœæœºåˆ¶ã€‘")
        if config['use_answer_consistency'] or config['use_entropy_halt']:
            if config['use_answer_consistency']:
                print(f"  âœ“ ç­”æ¡ˆä¸€è‡´æ€§æ£€æµ‹ (çª—å£={config['consistency_k']})")
            if config['use_entropy_halt']:
                print(f"  âœ“ ç†µå€¼æ£€æµ‹ (é˜ˆå€¼={config['entropy_threshold']}, æ­¥æ•°={config['entropy_steps']})")
        else:
            print(f"  âœ— æ—©åœæœºåˆ¶ç¦ç”¨")
        
        # æ£€æŸ¥ç‚¹å‚æ•°
        print(f"\n  ã€æ£€æŸ¥ç‚¹å‚æ•°ã€‘")
        print(f"  â±ï¸  æœ€å°tokens: {config['min_tokens']}")
        print(f"  â„ï¸  å†·å´tokens: {config['cooldown']}")
        print(f"  ğŸ“ å®Œæ•´å¥å­æ£€æŸ¥: {'âœ“' if config['check_after_complete_sentence'] else 'âœ—'}")
        
        # æ¢é’ˆå‚æ•°
        print(f"\n  ã€æ¢é’ˆå‚æ•°ã€‘")
        print(f"  ğŸ§ª æœ€å¤§æ¢é’ˆtokens: {config['max_probe_tokens']}")
        print(f"  ğŸŒ¡ï¸  æ¢é’ˆæ¸©åº¦: {config['probe_temperature']}")
        
        if show_title:
            print(f"\n{'='*80}\n")
    
    def show_dataset_menu(self) -> Optional[tuple]:
        """æ˜¾ç¤ºæ•°æ®é›†é€‰æ‹©èœå•"""
        self.show_header("é€‰æ‹©æ•°æ®é›†")
        
        index = 1
        index_map = {}
        
        for category, datasets in self.DATASETS.items():
            category_name = "GSM8Kæ•°æ®é›†" if category == "gsm8k" else "MATHæ•°æ®é›†"
            print(f"ã€{category_name}ã€‘")
            for key, info in datasets.items():
                print(f"  {index}. {info['name']:<25} ({info['size']}æ ·æœ¬)")
                index_map[str(index)] = (info['file'], info['size'])
                index += 1
            print()
        
        print("  0. è¿”å›ä¸»èœå•")
        print(f"\n{'='*80}\n")
        
        while True:
            choice = input("è¯·é€‰æ‹©æ•°æ®é›† [è¾“å…¥æ•°å­—]: ").strip()
            
            if choice == '0':
                return None
            
            if choice in index_map:
                return index_map[choice]
            
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def show_model_menu(self) -> Optional[str]:
        """æ˜¾ç¤ºæ¨¡å‹é€‰æ‹©èœå•"""
        self.show_header("é€‰æ‹©æ¨¡å‹")
        
        index = 1
        index_map = {}
        
        for key, info in self.MODELS.items():
            print(f"  {index}. {key:<20} - {info['desc']}")
            index_map[str(index)] = key
            index += 1
        
        print("\n  0. è¿”å›ä¸»èœå•")
        print(f"\n{'='*80}\n")
        
        while True:
            choice = input("è¯·é€‰æ‹©æ¨¡å‹ [è¾“å…¥æ•°å­—]: ").strip()
            
            if choice == '0':
                return None
            
            if choice in index_map:
                return index_map[choice]
            
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def main_menu(self) -> Optional[str]:
        """ä¸»èœå•"""
        self.show_header("HALT-CoT é…ç½®ç®¡ç†å™¨")
        self.show_config_summary(self.current_config, show_title=False)
        print(f"\n{'='*80}\n")
        
        print("ã€æ“ä½œèœå•ã€‘")
        print("  1. é€‰æ‹©æ¨¡å‹")
        print("  2. é€‰æ‹©æ•°æ®é›†")
        print("  3. ä¿®æ”¹ç”Ÿæˆå‚æ•° (tokens, æ¸©åº¦ç­‰)")
        print("  4. ä¿®æ”¹æ£€æµ‹æ¨¡å¼ (æ™ºèƒ½/å¥å­è¾¹ç•Œ)")
        print("  5. ä¿®æ”¹æ—©åœå‚æ•°")
        print("  6. ä¿®æ”¹æ£€æŸ¥ç‚¹å‚æ•°")
        print("  7. ä¿®æ”¹æ¢é’ˆå‚æ•°")
        print("  8. åˆ‡æ¢å¼€å…³é€‰é¡¹")
        print("  9. é‡ç½®ä¸ºé»˜è®¤é…ç½®")
        print()
        print("  s. ä¿å­˜å½“å‰é…ç½®")
        print("  0. é€€å‡º")
        print(f"\n{'='*80}\n")
        
        return input("è¯·é€‰æ‹©æ“ä½œ [è¾“å…¥æ•°å­—æˆ–å­—æ¯]: ").strip().lower()
    
    def modify_generation_params(self):
        """ä¿®æ”¹ç”Ÿæˆå‚æ•°"""
        self.show_header("ä¿®æ”¹ç”Ÿæˆå‚æ•°")
        
        print(f"å½“å‰é…ç½®:")
        print(f"  æ ·æœ¬æ•°é‡: {self.current_config['sample_size']}")
        print(f"  æœ€å¤§tokens: {self.current_config['max_tokens']}")
        print(f"  æ¸©åº¦å‚æ•°: {self.current_config['temperature']}")
        print()
        
        try:
            val = input("æ ·æœ¬æ•°é‡ (å›è½¦è·³è¿‡): ").strip()
            if val:
                self.current_config['sample_size'] = int(val)
                print(f"  âœ“ å·²ä¿®æ”¹ä¸º: {self.current_config['sample_size']}")
            
            val = input("æœ€å¤§tokens (å›è½¦è·³è¿‡): ").strip()
            if val:
                self.current_config['max_tokens'] = int(val)
                print(f"  âœ“ å·²ä¿®æ”¹ä¸º: {self.current_config['max_tokens']}")
            
            val = input("æ¸©åº¦å‚æ•° 0.0-2.0 (å›è½¦è·³è¿‡): ").strip()
            if val:
                self.current_config['temperature'] = float(val)
                print(f"  âœ“ å·²ä¿®æ”¹ä¸º: {self.current_config['temperature']}")
            
            print("\nâœ… å‚æ•°ä¿®æ”¹å®Œæˆ")
        except ValueError:
            print("\nâŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œä¿®æ”¹å·²å–æ¶ˆ")
        
        input("\næŒ‰å›è½¦ç»§ç»­...")
    
    def modify_detection_mode(self):
        """ä¿®æ”¹æ£€æµ‹æ¨¡å¼"""
        self.show_header("ä¿®æ”¹æ£€æµ‹æ¨¡å¼")
        
        print("ã€æ£€æµ‹æ¨¡å¼é€‰æ‹©ã€‘")
        print("  1. æ™ºèƒ½é˜¶æ®µæ£€æµ‹ (æ ¹æ®æ¨ç†é˜¶æ®µè‡ªåŠ¨æ£€æµ‹)")
        print("  2. å¥å­è¾¹ç•Œæ£€æµ‹ (æ¯å®Œæˆä¸€ä¸ªå¥å­åæ£€æµ‹) [æ¨è]")
        print("  3. ç¦ç”¨æ£€æµ‹ (ä»…ç”¨äºåŸºçº¿å¯¹æ¯”)")
        print()
        print("  0. è¿”å›")
        print()
        
        choice = input("è¯·é€‰æ‹©æ£€æµ‹æ¨¡å¼ [è¾“å…¥æ•°å­—]: ").strip()
        
        if choice == '1':
            self.current_config['use_smart_detection'] = True
            self.current_config['use_sentence_detection'] = False
            print("\nâœ… å·²åˆ‡æ¢åˆ°æ™ºèƒ½é˜¶æ®µæ£€æµ‹æ¨¡å¼")
        elif choice == '2':
            self.current_config['use_smart_detection'] = False
            self.current_config['use_sentence_detection'] = True
            print("\nâœ… å·²åˆ‡æ¢åˆ°å¥å­è¾¹ç•Œæ£€æµ‹æ¨¡å¼")
        elif choice == '3':
            self.current_config['use_smart_detection'] = False
            self.current_config['use_sentence_detection'] = False
            print("\nâœ… å·²ç¦ç”¨æ£€æµ‹æ¨¡å¼")
        elif choice == '0':
            return
        else:
            print("\nâŒ æ— æ•ˆé€‰æ‹©")
        
        input("\næŒ‰å›è½¦ç»§ç»­...")
    
    def modify_early_stop_params(self):
        """ä¿®æ”¹æ—©åœå‚æ•°"""
        self.show_header("ä¿®æ”¹æ—©åœå‚æ•°")
        
        print(f"å½“å‰é…ç½®:")
        print(f"  ç­”æ¡ˆä¸€è‡´æ€§æ£€æµ‹: {'âœ“' if self.current_config['use_answer_consistency'] else 'âœ—'}")
        print(f"  ç†µå€¼æ£€æµ‹: {'âœ“' if self.current_config['use_entropy_halt'] else 'âœ—'}")
        print(f"  ä¸€è‡´æ€§çª—å£: {self.current_config['consistency_k']}")
        print(f"  ç†µå€¼é˜ˆå€¼: {self.current_config['entropy_threshold']}")
        print(f"  è¿ç»­æ­¥æ•°: {self.current_config['entropy_steps']}")
        print()
        
        try:
            val = input("ä¸€è‡´æ€§çª—å£ (å›è½¦è·³è¿‡): ").strip()
            if val:
                self.current_config['consistency_k'] = int(val)
                print(f"  âœ“ å·²ä¿®æ”¹ä¸º: {self.current_config['consistency_k']}")
            
            val = input("ç†µå€¼é˜ˆå€¼ (å›è½¦è·³è¿‡): ").strip()
            if val:
                self.current_config['entropy_threshold'] = float(val)
                print(f"  âœ“ å·²ä¿®æ”¹ä¸º: {self.current_config['entropy_threshold']}")
            
            val = input("è¿ç»­æ­¥æ•° (å›è½¦è·³è¿‡): ").strip()
            if val:
                self.current_config['entropy_steps'] = int(val)
                print(f"  âœ“ å·²ä¿®æ”¹ä¸º: {self.current_config['entropy_steps']}")
            
            print("\nâœ… æ—©åœå‚æ•°ä¿®æ”¹å®Œæˆ")
        except ValueError:
            print("\nâŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œä¿®æ”¹å·²å–æ¶ˆ")
        
        input("\næŒ‰å›è½¦ç»§ç»­...")
    
    def modify_checkpoint_params(self):
        """ä¿®æ”¹æ£€æŸ¥ç‚¹å‚æ•°"""
        self.show_header("ä¿®æ”¹æ£€æŸ¥ç‚¹å‚æ•°")
        
        print(f"å½“å‰é…ç½®:")
        print(f"  æœ€å°tokens: {self.current_config['min_tokens']}")
        print(f"  å†·å´tokens: {self.current_config['cooldown']}")
        print()
        
        try:
            val = input("æœ€å°tokens (å¼€å§‹æ£€æµ‹å‰) (å›è½¦è·³è¿‡): ").strip()
            if val:
                self.current_config['min_tokens'] = int(val)
                print(f"  âœ“ å·²ä¿®æ”¹ä¸º: {self.current_config['min_tokens']}")
            
            val = input("å†·å´tokens (ä¸¤æ¬¡æ£€æµ‹é—´éš”) (å›è½¦è·³è¿‡): ").strip()
            if val:
                self.current_config['cooldown'] = int(val)
                print(f"  âœ“ å·²ä¿®æ”¹ä¸º: {self.current_config['cooldown']}")
            
            print("\nâœ… æ£€æŸ¥ç‚¹å‚æ•°ä¿®æ”¹å®Œæˆ")
        except ValueError:
            print("\nâŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œä¿®æ”¹å·²å–æ¶ˆ")
        
        input("\næŒ‰å›è½¦ç»§ç»­...")
    
    def modify_probe_params(self):
        """ä¿®æ”¹æ¢é’ˆå‚æ•°"""
        self.show_header("ä¿®æ”¹æ¢é’ˆå‚æ•°")
        
        print(f"å½“å‰é…ç½®:")
        print(f"  æœ€å¤§æ¢é’ˆtokens: {self.current_config['max_probe_tokens']}")
        print(f"  æ¢é’ˆæ¸©åº¦: {self.current_config['probe_temperature']}")
        print()
        
        try:
            val = input("æœ€å¤§æ¢é’ˆtokens (å›è½¦è·³è¿‡): ").strip()
            if val:
                self.current_config['max_probe_tokens'] = int(val)
                print(f"  âœ“ å·²ä¿®æ”¹ä¸º: {self.current_config['max_probe_tokens']}")
            
            val = input("æ¢é’ˆæ¸©åº¦ 0.0-1.0 (å›è½¦è·³è¿‡): ").strip()
            if val:
                self.current_config['probe_temperature'] = float(val)
                print(f"  âœ“ å·²ä¿®æ”¹ä¸º: {self.current_config['probe_temperature']}")
            
            print("\nâœ… æ¢é’ˆå‚æ•°ä¿®æ”¹å®Œæˆ")
        except ValueError:
            print("\nâŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œä¿®æ”¹å·²å–æ¶ˆ")
        
        input("\næŒ‰å›è½¦ç»§ç»­...")
    
    def toggle_switches(self):
        """åˆ‡æ¢å¼€å…³é€‰é¡¹"""
        self.show_header("åˆ‡æ¢å¼€å…³é€‰é¡¹")
        
        switches = {
            '1': ('do_sample', 'é‡‡æ ·æ¨¡å¼'),
            '2': ('verbose', 'è¯¦ç»†è¾“å‡º'),
            '3': ('debug', 'è°ƒè¯•æ¨¡å¼'),
            '4': ('save_results', 'ä¿å­˜ç»“æœ'),
            '5': ('use_answer_consistency', 'ç­”æ¡ˆä¸€è‡´æ€§æ£€æµ‹'),
            '6': ('use_entropy_halt', 'ç†µå€¼æ£€æµ‹'),
            '7': ('check_after_complete_sentence', 'å®Œæ•´å¥å­æ£€æŸ¥'),
        }
        
        while True:
            print(f"\nå½“å‰çŠ¶æ€:")
            for key, (config_key, name) in switches.items():
                status = 'âœ“ å¯ç”¨' if self.current_config[config_key] else 'âœ— ç¦ç”¨'
                print(f"  {key}. {name:<20} [{status}]")
            
            print("\n  0. è¿”å›ä¸»èœå•")
            print()
            
            choice = input("é€‰æ‹©è¦åˆ‡æ¢çš„é€‰é¡¹ (è¾“å…¥æ•°å­—): ").strip()
            
            if choice == '0':
                break
            
            if choice in switches:
                config_key, name = switches[choice]
                self.current_config[config_key] = not self.current_config[config_key]
                status = 'å¯ç”¨' if self.current_config[config_key] else 'ç¦ç”¨'
                print(f"  âœ“ {name}å·²{status}")
            else:
                print("  âŒ æ— æ•ˆé€‰æ‹©")
    
    def reset_to_default(self):
        """é‡ç½®ä¸ºé»˜è®¤é…ç½®"""
        confirm = input("\nâš ï¸ ç¡®è®¤é‡ç½®ä¸ºé»˜è®¤é…ç½®? (y/n): ").strip().lower()
        if confirm == 'y':
            self.current_config = self.DEFAULT_CONFIG.copy()
            print("âœ… å·²é‡ç½®ä¸ºé»˜è®¤é…ç½®")
        else:
            print("âŒ å·²å–æ¶ˆé‡ç½®")
        input("\næŒ‰å›è½¦ç»§ç»­...")
    
    def build_full_config(self) -> Dict[str, Any]:
        """æ„å»ºå®Œæ•´é…ç½®ï¼ˆç²¾ç®€ç‰ˆï¼‰"""
        # å¥å­ç»“æŸæ ‡è®°
        sentence_endings = [".", "!", "?", "ã€‚", "ï¼", "ï¼Ÿ"]
        
        # å·²çŸ¥ç¼©å†™è¯
        known_abbreviations = [
            "mr", "mrs", "ms", "dr", "prof", "sr", "jr",
            "etc", "vs", "i.e", "e.g", "approx", "est",
            "inc", "corp", "ltd", "co", "dept"
        ]
        
        return {
            "model_configs": {
                key: {"name": info["name"], "description": info["desc"]}
                for key, info in self.MODELS.items()
            },
            "active_model": self.current_config['active_model'],
            
            "experiment": {
                "sample_size": self.current_config['sample_size'],
                "verbose": self.current_config['verbose'],
                "save_results": self.current_config['save_results'],
                "max_new_tokens": self.current_config['max_tokens'],
                "temperature": self.current_config['temperature'],
                "do_sample": self.current_config['do_sample'],
                "debug_probe": self.current_config['debug']
            },
            
            "paths": {
                "test_data": f"data/{self.current_config['data']}"
            },
            
            "early_stopping": {
                "use_answer_consistency": self.current_config['use_answer_consistency'],
                "use_entropy_halt": self.current_config['use_entropy_halt'],
                "consistency_k": self.current_config['consistency_k'],
                "entropy_threshold": self.current_config['entropy_threshold'],
                "entropy_consecutive_steps": self.current_config['entropy_steps'],
                "min_tokens_before_check": self.current_config['min_tokens'],
                "cooldown_tokens": self.current_config['cooldown']
            },
            
            "stage_control": {
                "use_smart_detection": self.current_config['use_smart_detection']
            },
            
            "sentence_detection": {
                "enabled": self.current_config['use_sentence_detection'],
                "min_tokens_before_check": self.current_config['min_tokens'],
                "cooldown_tokens": self.current_config['cooldown'],
                "sentence_endings": sentence_endings,
                "known_abbreviations": known_abbreviations,
                "check_after_complete_sentence": self.current_config['check_after_complete_sentence']
            },
            
            "probe_system": {
                "max_probe_tokens": self.current_config['max_probe_tokens'],
                "probe_temperature": self.current_config['probe_temperature'],
                "probe_strategies": {
                    "calculation": "\n\nThe result of this calculation is: ",
                    "conclusion": "\n\nTherefore, the final answer is: ",
                    "answer_signal": "\n#### ",
                    "intermediate": "\n\nThe current value is: ",
                    "reasoning": "\n\nBased on the above, the answer is: "
                }
            },
            
            "reasoning_stage_markers": {
                "calculation": ["=", "equals", "total", "sum", "result", "calculate"],
                "conclusion": ["therefore", "thus", "so", "hence", "finally", "in conclusion"],
                "intermediate": ["step", "first", "next", "then", "now", "let's"],
                "answer_signal": ["answer is", "answer:", "####", "\\boxed", "final answer"],
                "reasoning": ["because", "since", "if", "when", "consider"]
            }
        }
    
    def save_config(self):
        """ä¿å­˜é…ç½®"""
        # å¤‡ä»½æ—§é…ç½®
        if self.current_config_path.exists():
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = self.backup_dir / f"config_{timestamp}.json"
            shutil.copy(self.current_config_path, backup_path)
            print(f"ğŸ“¦ å·²å¤‡ä»½æ—§é…ç½®åˆ°: {backup_path.name}")
        
        # ä¿å­˜æ–°é…ç½®
        full_config = self.build_full_config()
        with open(self.current_config_path, 'w', encoding='utf-8') as f:
            json.dump(full_config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {self.current_config_path}")
        
        # æ˜¾ç¤ºä¿å­˜çš„é…ç½®æ‘˜è¦
        print(f"\nä¿å­˜çš„é…ç½®æ‘˜è¦:")
        print(f"  æ¨¡å‹: {self.current_config['active_model']}")
        print(f"  æ•°æ®é›†: {self.current_config['data']} ({self.current_config['sample_size']}æ ·æœ¬)")
        
        if self.current_config['use_smart_detection']:
            print(f"  æ£€æµ‹æ¨¡å¼: æ™ºèƒ½é˜¶æ®µæ£€æµ‹")
        elif self.current_config['use_sentence_detection']:
            print(f"  æ£€æµ‹æ¨¡å¼: å¥å­è¾¹ç•Œæ£€æµ‹")
        else:
            print(f"  æ£€æµ‹æ¨¡å¼: ç¦ç”¨")
        
        early_stop_status = []
        if self.current_config['use_answer_consistency']:
            early_stop_status.append("ç­”æ¡ˆä¸€è‡´æ€§")
        if self.current_config['use_entropy_halt']:
            early_stop_status.append("ç†µå€¼æ£€æµ‹")
        
        if early_stop_status:
            print(f"  æ—©åœç­–ç•¥: {', '.join(early_stop_status)}")
        else:
            print(f"  æ—©åœç­–ç•¥: ç¦ç”¨")
        
        input("\næŒ‰å›è½¦ç»§ç»­...")
    
    def run(self):
        """è¿è¡Œäº¤äº’å¼é…ç½®"""
        while True:
            choice = self.main_menu()
            
            if choice == '0':
                print("\nğŸ‘‹ å·²é€€å‡ºé…ç½®ç®¡ç†å™¨\n")
                break
            
            elif choice == '1':
                # é€‰æ‹©æ¨¡å‹
                result = self.show_model_menu()
                if result:
                    self.current_config['active_model'] = result
                    model_info = self.MODELS[result]
                    print(f"\nâœ… å·²é€‰æ‹©æ¨¡å‹: {result} ({model_info['desc']})")
                    input("æŒ‰å›è½¦ç»§ç»­...")
            
            elif choice == '2':
                # é€‰æ‹©æ•°æ®é›†
                result = self.show_dataset_menu()
                if result:
                    data_file, sample_size = result
                    self.current_config['data'] = data_file
                    self.current_config['sample_size'] = sample_size
                    print(f"\nâœ… å·²é€‰æ‹©æ•°æ®é›†: {data_file} ({sample_size}æ ·æœ¬)")
                    input("æŒ‰å›è½¦ç»§ç»­...")
            
            elif choice == '3':
                # ä¿®æ”¹ç”Ÿæˆå‚æ•°
                self.modify_generation_params()
            
            elif choice == '4':
                # ä¿®æ”¹æ£€æµ‹æ¨¡å¼
                self.modify_detection_mode()
            
            elif choice == '5':
                # ä¿®æ”¹æ—©åœå‚æ•°
                self.modify_early_stop_params()
            
            elif choice == '6':
                # ä¿®æ”¹æ£€æŸ¥ç‚¹å‚æ•°
                self.modify_checkpoint_params()
            
            elif choice == '7':
                # ä¿®æ”¹æ¢é’ˆå‚æ•°
                self.modify_probe_params()
            
            elif choice == '8':
                # åˆ‡æ¢å¼€å…³é€‰é¡¹
                self.toggle_switches()
            
            elif choice == '9':
                # é‡ç½®ä¸ºé»˜è®¤é…ç½®
                self.reset_to_default()
            
            elif choice == 's':
                # ä¿å­˜é…ç½®
                self.save_config()
            
            else:
                print("\nâŒ æ— æ•ˆé€‰æ‹©")
                input("æŒ‰å›è½¦ç»§ç»­...")


def main():
    """ä¸»å‡½æ•°"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                            â•‘
â•‘                    HALT-CoT äº¤äº’å¼é…ç½®ç®¡ç†å™¨ v2.0                          â•‘
â•‘                                                                            â•‘
â•‘                    æ”¯æŒå¥å­è¾¹ç•Œæ£€æµ‹ & æ™ºèƒ½é˜¶æ®µæ£€æµ‹                         â•‘
â•‘                                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    manager = InteractiveConfigManager()
    manager.run()


if __name__ == "__main__":
    main()
